{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a51a9b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from networkx.readwrite import graphml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d20aba2",
   "metadata": {},
   "source": [
    "### Datasets for KG creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fea0caba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets to be processed: dict_keys(['train', 'dev', 'test', 'test_ood'])\n"
     ]
    }
   ],
   "source": [
    "#Input triplets (taken from postprocessed documents)\n",
    "datasets = {\n",
    "    'train': 'postprocessed-dataset/train_chunks.json',\n",
    "    'dev': 'postprocessed-dataset/dev_chunks.json',\n",
    "    'test': 'postprocessed-dataset/test_chunks.json',\n",
    "    'test_ood': 'postprocessed-dataset/test_ood_chunks.json' \n",
    "}\n",
    "print(\"Datasets to be processed:\", datasets.keys())\n",
    "\n",
    "G = nx.MultiDiGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06382213",
   "metadata": {},
   "source": [
    "### Function for entity stripping of label\n",
    "triplets in this dataset follow the following structure:\n",
    "\n",
    "$$[subject:label,relationship,object:label]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8fa54527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_entity(e):\n",
    "    if \":\" in e:\n",
    "        label, etype = e.split(\":\", 1)\n",
    "    else:\n",
    "        label, etype = e, None\n",
    "    return label.strip(), etype.strip() if etype else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dade2e76",
   "metadata": {},
   "source": [
    "### Reading datasets and KG creation\n",
    "Each dataset contains the following fields:\n",
    "- doc_id — Unique identifier for the source document.\n",
    "- chunk_id — Identifier for the text chunk or segment within the document.\n",
    "- relations — List of extracted relations, where each relation follows the structure:\n",
    "    - subject:label, relationship, object:label\n",
    "\n",
    "\n",
    "During processing, the system reads each entry and:\n",
    "- Creates a node for every unique entity (subject and object).\n",
    "- Creates an edge between those nodes representing the specified relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e60b3c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing postprocessed-dataset/train_chunks.json...\n",
      "Processing postprocessed-dataset/dev_chunks.json...\n",
      "Processing postprocessed-dataset/test_chunks.json...\n",
      "Processing postprocessed-dataset/test_ood_chunks.json...\n"
     ]
    }
   ],
   "source": [
    "for split, filepath in datasets.items():\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        print(f\"Processing {filepath}...\")\n",
    "        data = json.load(f)\n",
    "        for item in data:\n",
    "            doc_id = item.get('doc_id')\n",
    "            chunk_id = item.get('chunk_id')\n",
    "            relations = item.get('relations', [])\n",
    "\n",
    "            for i,(entity1, rel, entity2) in enumerate(relations):\n",
    "                entity1_label, entity1_type = parse_entity(entity1)\n",
    "                entity2_label, entity2_type = parse_entity(entity2)\n",
    "\n",
    "                G.add_node(entity1_label, type=entity1_type)\n",
    "                G.add_node(entity2_label, type=entity2_type)\n",
    "                print\n",
    "                \n",
    "                #Because MultiDiGraph allows multiple edges between nodes, we create a unique key for each edge, \n",
    "                # if not gephi will warn that a key with a ID already exists.\n",
    "                edge_key = f\"{entity1_label}_{entity2_label}_{doc_id}_{chunk_id}_{i}\"\n",
    "\n",
    "                G.add_edge(\n",
    "                    entity1_label,\n",
    "                    entity2_label,\n",
    "                    key=edge_key,\n",
    "                    relation=rel,\n",
    "                    doc_id=doc_id,\n",
    "                    chunk_id=chunk_id\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3569b7",
   "metadata": {},
   "source": [
    "### Saving knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6c7bb80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 5640, Edges: 12083\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"Knowledge-graph\", exist_ok=True)\n",
    "\n",
    "graph_path = os.path.join(\"Knowledge-graph\", \"kg_total.graphml\")\n",
    "nx.write_graphml(G, graph_path)\n",
    "\n",
    "print(f\"Nodes: {len(G.nodes)}, Edges: {len(G.edges)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aa9b91cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kg(name,input_file):\n",
    "    graph = nx.MultiDiGraph()\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        print(f\"Processing {input_file}...\")\n",
    "        data = json.load(f)\n",
    "        for item in data:\n",
    "            doc_id = item.get('doc_id')\n",
    "            chunk_id = item.get('chunk_id')\n",
    "            relations = item.get('relations', [])\n",
    "\n",
    "            for i,(entity1, rel, entity2) in enumerate(relations):\n",
    "                entity1_label, entity1_type = parse_entity(entity1)\n",
    "                entity2_label, entity2_type = parse_entity(entity2)\n",
    "\n",
    "                graph.add_node(entity1_label, type=entity1_type)\n",
    "                graph.add_node(entity2_label, type=entity2_type)\n",
    "                print\n",
    "                \n",
    "                # Because MultiDiGraph allows multiple edges between nodes, we create a unique key for each edge, \n",
    "                # if not gephi will warn that a key with a ID already exists.\n",
    "                edge_key = f\"{entity1_label}_{entity2_label}_{doc_id}_{chunk_id}_{i}\"\n",
    "\n",
    "                graph.add_edge(\n",
    "                    entity1_label,\n",
    "                    entity2_label,\n",
    "                    key=edge_key,\n",
    "                    relation=rel,\n",
    "                    doc_id=doc_id,\n",
    "                    chunk_id=chunk_id\n",
    "            )\n",
    "\n",
    "    os.makedirs(\"Knowledge-graph\", exist_ok=True)\n",
    "\n",
    "    graph_path = os.path.join(\"Knowledge-graph\", f\"kg_{name}.graphml\")\n",
    "    nx.write_graphml(graph, graph_path)\n",
    "\n",
    "    print(f\"Nodes: {len(graph.nodes)}, Edges: {len(graph.edges)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "09cd4fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing postprocessed-dataset/train_chunks.json...\n",
      "Nodes: 4164, Edges: 8743\n",
      "Processing postprocessed-dataset/dev_chunks.json...\n",
      "Nodes: 646, Edges: 1132\n",
      "Processing postprocessed-dataset/test_chunks.json...\n",
      "Nodes: 969, Edges: 1626\n",
      "Processing postprocessed-dataset/test_ood_chunks.json...\n",
      "Nodes: 407, Edges: 582\n"
     ]
    }
   ],
   "source": [
    "extract_kg('train', datasets['train'])\n",
    "extract_kg('dev', datasets['dev'])\n",
    "extract_kg('test', datasets['test'])\n",
    "extract_kg('test_ood', datasets['test_ood'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
