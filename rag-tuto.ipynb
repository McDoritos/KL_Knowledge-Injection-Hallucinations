{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4e8dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACCING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbdb87d",
   "metadata": {},
   "source": [
    "#### Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a125465",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini:\")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"google_genai:gemini-2.5-flash-lite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2b646f",
   "metadata": {},
   "source": [
    "#### Embeddings Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09272b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba13f27a",
   "metadata": {},
   "source": [
    "#### Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24ae227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003c7b1b",
   "metadata": {},
   "source": [
    "#### Loading Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c70dd1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43047\n",
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")\n",
    "\n",
    "print(docs[0].page_content[:500])  # Print the first 500 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca52dda6",
   "metadata": {},
   "source": [
    "#### Splitting documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e2117ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 63 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True,\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133e5876",
   "metadata": {},
   "source": [
    "#### Storing Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c5eb1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['416da468-c613-413b-9316-0f1646833b65', 'd25b4d74-5f09-4cf0-bb51-a488dcbf2e2f', '5a46c90b-2d67-47bd-8eb9-417ea83fca24']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b582fa37",
   "metadata": {},
   "source": [
    "#### RAG Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3d5ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d8c387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "\n",
    "tools = [retrieve_context]\n",
    "# If desired, specify custom instructions\n",
    "prompt = (\n",
    "    \"You have access to a tool that retrieves context from a blog post. \"\n",
    "    \"Use the tool to help answer user queries.\"\n",
    ")\n",
    "\n",
    "agent = initialize_agent(tools, model, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True, system_message=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c943f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ppcro\\AppData\\Local\\Temp\\ipykernel_26736\\4017068743.py:7: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = agent.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find the standard method for Task Decomposition. I will use the `retrieve_context` tool to search for this information. Once I have the standard method, I will then search for common extensions of that method.\n",
      "Action: retrieve_context\n",
      "Action Input: standard method for Task Decomposition\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSource: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17734}\n",
      "Content: The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can't be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe provided context describes three methods for task decomposition: (1) using LLM with simple prompting, (2) using task-specific instructions, and (3) with human inputs. It also mentions an approach called LLM+P which uses an external classical planner with PDDL. The question asks for the *standard* method. The first method, \"LLM with simple prompting,\" appears to be the most general and directly applicable to breaking down tasks into steps. The LLM+P method is described as \"quite distinct\" and relies on external tools and specific domain knowledge (PDDL), suggesting it's not the universally standard method. Therefore, LLM with simple prompting seems to be the most fitting answer for the standard method.\n",
      "\n",
      "Now I need to find common extensions of this method. I will search for extensions related to LLM-based task decomposition or agentic task decomposition.\n",
      "Action: retrieve_context\n",
      "Action Input: extensions of LLM-based task decomposition\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSource: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe first search result identified three methods for task decomposition: LLM with simple prompting, task-specific instructions, and human inputs. It also introduced LLM+P which uses external classical planners. The second search result mentions Chain of Thought (CoT) as a \"standard prompting technique\" for task decomposition by instructing the model to \"think step by step.\" This aligns well with the \"LLM with simple prompting\" method from the first result. The second result also introduces \"Tree of Thoughts\" (ToT) as an extension of CoT.\n",
      "\n",
      "Therefore, the standard method for task decomposition appears to be using LLMs with simple prompting, often exemplified by Chain of Thought (CoT). Common extensions include more advanced prompting techniques like Tree of Thoughts (ToT) and approaches that integrate with external planning tools like LLM+P.\n",
      "\n",
      "I have enough information to answer the question.\n",
      "Final Answer: The standard method for task decomposition is by using LLMs with simple prompting, such as instructing the model to \"think step by step\" (Chain of Thought - CoT). Common extensions of this method include Tree of Thoughts (ToT), which explores multiple reasoning possibilities at each step by generating multiple thoughts and creating a tree structure, and LLM+P, which relies on external classical planners and the Planning Domain Definition Language (PDDL) for long-horizon planning. Other methods include using task-specific instructions or human inputs.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The standard method for task decomposition is by using LLMs with simple prompting, such as instructing the model to \"think step by step\" (Chain of Thought - CoT). Common extensions of this method include Tree of Thoughts (ToT), which explores multiple reasoning possibilities at each step by generating multiple thoughts and creating a tree structure, and LLM+P, which relies on external classical planners and the Planning Domain Definition Language (PDDL) for long-horizon planning. Other methods include using task-specific instructions or human inputs.\n"
     ]
    }
   ],
   "source": [
    "query = (\n",
    "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
    "    \"Once you get the answer, look up common extensions of that method.\"\n",
    ")\n",
    "\n",
    "# Execução simples (mais robusta que usar .stream se o agente não suportar streaming)\n",
    "result = agent.run(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9811336b",
   "metadata": {},
   "source": [
    "#### RAG Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e35070af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "def make_agent_with_context(query: str):\n",
    "    retrieved_docs = vector_store.similarity_search(query)\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "    system_message = (\n",
    "        \"You are a helpful assistant. Use the following context in your response:\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    # Passe a tool aqui (não uma lista vazia)\n",
    "    tools = [retrieve_context]\n",
    "    agent = initialize_agent(\n",
    "        tools,\n",
    "        model,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "        system_message=system_message,\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6131e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to define what \"task decomposition\" is. I should use the retrieve_context tool to find information about this term.\n",
      "Action: retrieve_context\n",
      "Action Input: What is task decomposition?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSource: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe user is asking for a definition of \"task decomposition\". I have retrieved information that explains what task decomposition is and how it can be achieved. I can now synthesize this information to answer the question.\n",
      "Final Answer: Task decomposition is a process where complex tasks are broken down into smaller, simpler, and more manageable steps. This is often achieved using techniques like Chain of Thought (CoT) prompting, where the model is instructed to \"think step by step\" to decompose a task. Other methods include using task-specific instructions, human input, or even external classical planners that translate problems into a Planning Domain Definition Language (PDDL) for planning. The goal is to make complex tasks easier to handle and to provide insight into the agent's thinking process.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Task decomposition is a process where complex tasks are broken down into smaller, simpler, and more manageable steps. This is often achieved using techniques like Chain of Thought (CoT) prompting, where the model is instructed to \"think step by step\" to decompose a task. Other methods include using task-specific instructions, human input, or even external classical planners that translate problems into a Planning Domain Definition Language (PDDL) for planning. The goal is to make complex tasks easier to handle and to provide insight into the agent's thinking process.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is task decomposition?\"\n",
    "agent = make_agent_with_context(query)\n",
    "result = agent.run(query)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
